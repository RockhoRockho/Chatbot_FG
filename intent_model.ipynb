{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62d06b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 필요한 모듈 임포트\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14ec417d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# ① 데이터 읽어오기\n",
    "train_file = os.path.join('./models/intent', \"Intent_train_data.csv\")\n",
    "df = pd.read_csv(train_file, delimiter=',', header=None)\n",
    "df = df[[0, 1, 2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e646407c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['query', 'intent', 'intent_info']\n",
    "seq_len = list(map(lambda x : len(x.split(' ')), df['query']))\n",
    "max(seq_len)  # 문장 최대길이"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f67d6e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 시퀀스 벡터 크기\n",
    "MAX_SEQ_LEN = max(seq_len)\n",
    "\n",
    "def GlobalParams():\n",
    "    global MAX_SEQ_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "107ca845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# '질문(query)' 과 '의도(intent)'\n",
    "queries = df['query'].tolist()\n",
    "intents = df['intent'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36d97774",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['빵종류?',\n",
       " '종류?',\n",
       " '음료종류?',\n",
       " '커피종류?',\n",
       " '식사종류?',\n",
       " '에이드종류?',\n",
       " '사이드메뉴는 뭐 있어?',\n",
       " '사이드 메뉴는 뭐 있어?',\n",
       " '빵종류는 뭐 있어?',\n",
       " '종류는 뭐 있어?',\n",
       " '음료종류는 뭐 있어?',\n",
       " '커피종류는 뭐 있어?',\n",
       " '식사종류는 뭐 있어?',\n",
       " '에이드종류는 뭐 있어?',\n",
       " '사이드메뉴는?',\n",
       " '사이드 메뉴는?',\n",
       " '빵종류는?',\n",
       " '종류는?',\n",
       " '음료종류는?',\n",
       " '커피종류는?']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ac318ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "intents[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "647f12cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 모듈 불러오기\n",
    "from utils.Preprocess import Preprocess\n",
    "p = Preprocess(word2index_dic=os.path.join('./train_tools/dict', 'chatbot_dict.bin'),\n",
    "               userdic=os.path.join('./utils', 'train.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "95e569ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import json\n",
    "# special_token = json.load(open(\"special_token.json\"))\n",
    "# special_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "982584cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from transformers import ElectraTokenizer\n",
    "\n",
    "# tokenizer = ElectraTokenizer.from_pretrained(\"monologg/koelectra-base-v3-discriminator\") # 전처리 모듈 불러오기\n",
    "# tokenizer.add_special_tokens(special_token)\n",
    "\n",
    "# sequences = []\n",
    "\n",
    "# for sentence in queries:\n",
    "#     pos = tokenizer.tokenize(sentence)\n",
    "\n",
    "#     seq = tokenizer.convert_tokens_to_ids(pos)\n",
    "#     sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "417a948b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.tokenize('테이크아웃')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0a000d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 시퀀스 생성 (가장 시간 많이 걸림)\n",
    "# 해당 단어에 매칭되는 번호로 시퀀스 생성\n",
    "\n",
    "# ★ 시간 제법 걸림 * 몇십초 정도..\n",
    "\n",
    "sequences = []\n",
    "for sentence in queries:\n",
    "    pos = p.pos(sentence)\n",
    "    keywords = p.get_keywords(pos, without_tag=True)\n",
    "    seq = p.get_wordidx_sequence(keywords)\n",
    "    sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a524bd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lens = []\n",
    "for i in sequences:\n",
    "    lens.append(len(i))\n",
    "max(lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1884e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ② 단어 인덱스 시퀀스 벡터 \n",
    "# 단어 시퀀스 벡터 크기 (MAX_SEQ_LEN 로 동일하게 맞추기, 패딩처리)\n",
    "from config.GlobalParams import MAX_SEQ_LEN\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a5febcbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # ② 단어 인덱스 시퀀스 벡터 \n",
    "# # 단어 시퀀스 벡터 크기 (MAX_SEQ_LEN 로 동일하게 맞추기, 패딩처리)\n",
    "# from config.GlobalParams_Electra import MAX_SEQ_LEN\n",
    "# padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=MAX_SEQ_LEN, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7a29c9d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   1,    0,    0, ...,    0,    0,    0],\n",
       "       [8941,    0,    0, ...,    0,    0,    0],\n",
       "       [   1,    0,    0, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [   1,    3,    2, ...,    0,    0,    0],\n",
       "       [   1,    3,    2, ...,    0,    0,    0],\n",
       "       [   1,    3,    2, ...,    0,    0,    0]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db68aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17751"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(p.word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ac8b76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "96d7ae27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(tokenizer.additional_special_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49002a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ③ 학습용, 검증용, 테스트용 데이터셋 생성\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, intents)) # 패딩처리된 시퀀스와 의도(intent) 리스트 전체를 데이터셋 객체로\n",
    "ds = ds.shuffle(len(queries), seed=12) # 랜덤 섞기\n",
    "\n",
    "# 학습셋:검셋:테스트셋 = 7:2:1\n",
    "train_size = int(len(padded_seqs) * 0.7)\n",
    "val_size = int(len(padded_seqs) * 0.2)\n",
    "test_size = int(len(padded_seqs) * 0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "# 하이퍼 파라미터 설정\n",
    "dropout_prob = 0.5\n",
    "EMB_SIZE = 128\n",
    "EPOCH = 10\n",
    "# VOCAB_SIZE = tokenizer.vocab_size + len(tokenizer.additional_special_tokens) + 1 #전체 단어 개수\n",
    "VOCAB_SIZE = len(p.word_index) + 1 #전체 단어 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68d55db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ④ CNN 모델 정의\n",
    "# keras 함수형 모델 방식으로 구현\n",
    "input_layer = Input(shape=(MAX_SEQ_LEN,))  # 입력크기\n",
    "embedding_layer = Embedding(VOCAB_SIZE, EMB_SIZE, input_length=MAX_SEQ_LEN)(input_layer)\n",
    "dropout_emb = Dropout(rate=dropout_prob)(embedding_layer)\n",
    "\n",
    "conv1 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=3,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool1 = GlobalMaxPool1D()(conv1)\n",
    "\n",
    "conv2 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=4,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool2 = GlobalMaxPool1D()(conv2)\n",
    "\n",
    "conv3 = Conv1D(\n",
    "    filters=128,\n",
    "    kernel_size=5,\n",
    "    padding='valid',\n",
    "    activation=tf.nn.relu)(dropout_emb)\n",
    "pool3 = GlobalMaxPool1D()(conv3)\n",
    "\n",
    "# 3,4,5gram 이후 합치기\n",
    "concat = concatenate([pool1, pool2, pool3])\n",
    "\n",
    "hidden = Dense(128, activation=tf.nn.relu)(concat)\n",
    "dropout_hidden = Dropout(rate=dropout_prob)(hidden)\n",
    "logits = Dense(10, name='logits')(dropout_hidden)  # 최종적으로 12가의 의도 클래스를 분류. 결과로 나온 값(logits) 을을 점수(score) 라 부른다\n",
    "predictions = Dense(10, activation=tf.nn.softmax)(logits)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f016fbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ⑤ 모델 생성 \n",
    "model = Model(inputs=input_layer, outputs=predictions)\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41289bb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 10, 128)      2272256     ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 10, 128)      0           ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " conv1d (Conv1D)                (None, 8, 128)       49280       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 7, 128)       65664       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 6, 128)       82048       ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['conv1d[0][0]']                 \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " global_max_pooling1d_1 (Global  (None, 128)         0           ['conv1d_1[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " global_max_pooling1d_2 (Global  (None, 128)         0           ['conv1d_2[0][0]']               \n",
      " MaxPooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 384)          0           ['global_max_pooling1d[0][0]',   \n",
      "                                                                  'global_max_pooling1d_1[0][0]', \n",
      "                                                                  'global_max_pooling1d_2[0][0]'] \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 128)          49280       ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 128)          0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " logits (Dense)                 (None, 10)           1290        ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 10)           110         ['logits[0][0]']                 \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 2,519,928\n",
      "Trainable params: 2,519,928\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0f5bb74d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "380/380 [==============================] - 14s 34ms/step - loss: 0.8859 - accuracy: 0.7035 - val_loss: 0.2228 - val_accuracy: 0.9300\n",
      "Epoch 2/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.2313 - accuracy: 0.9264 - val_loss: 0.1408 - val_accuracy: 0.9433\n",
      "Epoch 3/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.2069 - accuracy: 0.9289 - val_loss: 0.1353 - val_accuracy: 0.9581\n",
      "Epoch 4/10\n",
      "380/380 [==============================] - 12s 31ms/step - loss: 0.1795 - accuracy: 0.9355 - val_loss: 0.1419 - val_accuracy: 0.9452\n",
      "Epoch 5/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.1672 - accuracy: 0.9406 - val_loss: 0.1343 - val_accuracy: 0.9493\n",
      "Epoch 6/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.1587 - accuracy: 0.9404 - val_loss: 0.1283 - val_accuracy: 0.9512\n",
      "Epoch 7/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.1527 - accuracy: 0.9435 - val_loss: 0.1279 - val_accuracy: 0.9470\n",
      "Epoch 8/10\n",
      "380/380 [==============================] - 13s 33ms/step - loss: 0.1466 - accuracy: 0.9467 - val_loss: 0.1208 - val_accuracy: 0.9465\n",
      "Epoch 9/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.1495 - accuracy: 0.9415 - val_loss: 0.1282 - val_accuracy: 0.9479\n",
      "Epoch 10/10\n",
      "380/380 [==============================] - 12s 32ms/step - loss: 0.1462 - accuracy: 0.9430 - val_loss: 0.1329 - val_accuracy: 0.9452\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x28c9e800a60>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델학습\n",
    "# ★ 시간 걸림 ★ \n",
    "checkpoint_cb = keras.callbacks.ModelCheckpoint('./models/intent/intent_model.h5', save_best_only=True) # 제일 좋은 모델 저장\n",
    "early_stopping_cb = keras.callbacks.EarlyStopping(patience=2, restore_best_weights=True)\n",
    "model.fit(train_ds, validation_data=val_ds, epochs=EPOCH, verbose=1,\n",
    "         callbacks=[checkpoint_cb, early_stopping_cb])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "69ceaf09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "55/55 [==============================] - 0s 2ms/step - loss: 0.1312 - accuracy: 0.9530\n",
      "Accuracy: 95.299542\n",
      "loss: 0.131209\n"
     ]
    }
   ],
   "source": [
    "# ⑦ 모델 평가(테스트 데이터 셋 이용)\n",
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print('Accuracy: %f' % (accuracy * 100))\n",
    "print('loss: %f' % (loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f3cd37",
   "metadata": {},
   "source": [
    "## Word2index_Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "13be27d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Preprocess import Preprocess\n",
    "from models.intent.IntentModel import IntentModel\n",
    "import os\n",
    "\n",
    "p = Preprocess(word2index_dic=os.path.join('./train_tools/dict', 'chatbot_dict.bin'),\n",
    "               userdic=os.path.join('./utils', 'train.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "54c5f238",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent = IntentModel(model_name=os.path.join('./models/intent', 'intent_model.h5'), preprocess=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7872aaf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"메뉴 보여줘\" # 필수항목 : 메뉴, 메뉴판, 주문, 결제, 포인트, 할인, 원산지, 텀블러, 영업시간, 테이크아웃, 추천, 화장실, 와이파이, 주문취소, 취소, 아메리카노\n",
    "\n",
    "# 1번 모델이 우세\n",
    "\n",
    "# 메뉴판 0  - 뒷문장 없니? 없나? 있나? \n",
    "# 테이크아웃\n",
    "# 영업시간\n",
    "# 원산지 5\n",
    "# 와이파이 6\n",
    "# 취소 - 메뉴 + 취소"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "a9b656dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = intent.predict_class(query)\n",
    "predict_label = intent.labels[predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c7c98d02",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "메뉴 보여줘\n",
      "의도 예측 클래스 :  0\n",
      "의도 예측 레이블 :  메뉴판 요구\n"
     ]
    }
   ],
   "source": [
    "print(query)\n",
    "print('의도 예측 클래스 : ', predict)\n",
    "print('의도 예측 레이블 : ', predict_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc684527",
   "metadata": {},
   "source": [
    "# ELECTRA_TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b9985b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.Preprocess import Preprocess\n",
    "from models.intent.IntentModel_Electra import IntentModel\n",
    "import os\n",
    "\n",
    "p = Preprocess(word2index_dic=os.path.join('./train_tools/dict', 'chatbot_dict.bin'),\n",
    "               userdic=os.path.join('./utils', 'train.tsv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "edcf3b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "intent = IntentModel(model_name=os.path.join('./models/intent', 'intent_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4df8cf80",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"주문\" # 필수항목 : 메뉴, 메뉴판, 주문, 결제, 포인트, 할인, 원산지, 텀블러, 영업시간, 테이크아웃, 추천, 화장실, 와이파이, 주문취소, 취소, 아메리카노\n",
    "\n",
    "# 메뉴판 0\n",
    "# 메뉴\n",
    "# 원산지 5\n",
    "# 와이파이 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "71633d92",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 15)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Users\\2020M~1\\AppData\\Local\\Temp/ipykernel_10068/2904120171.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mpredict_label\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mintent\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\github\\Chatbot_FG\\models\\intent\\IntentModel_Electra.py\u001b[0m in \u001b[0;36mpredict_class\u001b[1;34m(self, query)\u001b[0m\n\u001b[0;32m     40\u001b[0m             \u001b[0mpadded_seqs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msequence\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpad_sequences\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msequences\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mMAX_SEQ_LEN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'post'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m             \u001b[0mpredict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpadded_seqs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m             \u001b[0mpredict_class\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mpredict_class\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\func_graph.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1145\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint:disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1146\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ag_error_metadata\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1147\u001b[1;33m               \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1148\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1149\u001b[0m               \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1801, in predict_function  *\n        return step_function(self, iterator)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1790, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1783, in run_step  **\n        outputs = model.predict_step(data)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\training.py\", line 1751, in predict_step\n        return self(x, training=False)\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 67, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\ProgramData\\Anaconda3\\lib\\site-packages\\keras\\engine\\input_spec.py\", line 264, in assert_input_compatibility\n        raise ValueError(f'Input {input_index} of layer \"{layer_name}\" is '\n\n    ValueError: Input 0 of layer \"model\" is incompatible with the layer: expected shape=(None, 10), found shape=(None, 15)\n"
     ]
    }
   ],
   "source": [
    "predict = intent.predict_class(query)\n",
    "predict_label = intent.labels[predict]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b3961a1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(query)\n",
    "print('의도 예측 클래스 : ', predict)\n",
    "print('의도 예측 레이블 : ', predict_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a49873c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae149a08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
